{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gfFV8S8SWLE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Prevent TensorFlow GPU memory grabbing\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
        "\n",
        "# Fix TensorFlow layout optimizer bugs\n",
        "os.environ[\"TF_DISABLE_OPTIMIZER_IN_LAYOUT\"] = \"1\"\n",
        "os.environ[\"TF_DISABLE_LAYOUT_OPTIMIZER\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n40JarE7yEGY"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FAST + MEMORY EFFICIENT RETINA vs NON-RETINA CLASSIFIER\n",
        "# EfficientNetB3 + Mixed Precision + tf.data (no CLAHE)\n",
        "# Output: retina_model_best.h5 (for your app.py)\n",
        "# ============================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras import mixed_precision\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# ============================================================\n",
        "# MIXED PRECISION (Fast + Accurate)\n",
        "# ============================================================\n",
        "policy = mixed_precision.Policy(\"mixed_float16\")\n",
        "mixed_precision.set_global_policy(policy)\n",
        "print(\"Mixed Precision:\", mixed_precision.global_policy())\n",
        "\n",
        "# ============================================================\n",
        "# MOUNT DRIVE (Your dataset is in Drive)\n",
        "# ============================================================\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ZIP_PATH = \"/content/drive/MyDrive/retina_nonretina_dataset_balanced2.zip\"\n",
        "EXTRACT_PATH = \"/content/retina_nonretina_dataset_balanced2\"\n",
        "\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "print(\"Extracting dataset...\")\n",
        "with ZipFile(ZIP_PATH, 'r') as z:\n",
        "    z.extractall(EXTRACT_PATH)\n",
        "\n",
        "train_dir = f\"{EXTRACT_PATH}/train\"\n",
        "val_dir   = f\"{EXTRACT_PATH}/val\"\n",
        "\n",
        "print(\"Train:\", train_dir)\n",
        "print(\"Val:\", val_dir)\n",
        "\n",
        "# ============================================================\n",
        "# LOAD DATASET (FAST tf.data pipeline)\n",
        "# ============================================================\n",
        "IMG_SIZE = (300, 300)\n",
        "BATCH_SIZE = 16      # safe + fast\n",
        "SEED = 42\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    label_mode=\"categorical\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    label_mode=\"categorical\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Class indices:\", train_ds.class_names)\n",
        "\n",
        "# ============================================================\n",
        "# GPU AUGMENTATION + EFFICIENTNET PREPROCESS\n",
        "# ============================================================\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess\n",
        "\n",
        "def augment(images, labels):\n",
        "    images = tf.image.random_flip_left_right(images)\n",
        "    images = tf.image.random_brightness(images, max_delta=0.12)\n",
        "    images = tf.image.random_contrast(images, 0.85, 1.15)\n",
        "    images = tf.image.random_saturation(images, 0.9, 1.1)\n",
        "    return images, labels\n",
        "\n",
        "def preprocess(images, labels):\n",
        "    images = tf.cast(images, tf.float32)\n",
        "    images = eff_preprocess(images)\n",
        "    return images, labels\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .shuffle(512)\n",
        "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
        "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "val_ds = (\n",
        "    val_ds\n",
        "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# BUILD EfficientNetB3 MODEL\n",
        "# ============================================================\n",
        "base = tf.keras.applications.EfficientNetB3(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(300,300,3)\n",
        ")\n",
        "\n",
        "# Create classifier head\n",
        "inputs = layers.Input(shape=(300,300,3), dtype=tf.float32)\n",
        "x = base(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(256, activation=\"relu\", dtype=\"float32\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.summary()\n",
        "\n",
        "# ============================================================\n",
        "# STAGE 1 TRAINING â€” Freeze Backbone\n",
        "# ============================================================\n",
        "for layer in base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"retina_model_best.h5\",\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\"\n",
        ")\n",
        "\n",
        "earlystop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=6,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.3,\n",
        "    patience=3\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ”µ Stage 1 training...\")\n",
        "history1 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=2,\n",
        "    callbacks=[checkpoint, earlystop, reduce_lr]\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# STAGE 2 â€” UNFREEZE ALL + FINE-TUNE\n",
        "# ============================================================\n",
        "for layer in base.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"\\nðŸŸ¢ Stage 2 fine-tuning...\")\n",
        "history2 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[checkpoint, earlystop, reduce_lr]\n",
        ")\n",
        "\n",
        "# Final save\n",
        "model.save(\"retina_model_final.h5\")\n",
        "print(\"\\nâœ” Saved final: retina_model_final.h5\")\n",
        "print(\"âœ” Saved best:  retina_model_best.h5\")\n",
        "\n",
        "# ============================================================\n",
        "# UPLOAD TO DRIVE\n",
        "# ============================================================\n",
        "import shutil\n",
        "shutil.copy(\"retina_model_best.h5\", \"/content/drive/MyDrive/retina_model_best.h5\")\n",
        "shutil.copy(\"retina_model_final.h5\", \"/content/drive/MyDrive/retina_model_final.h5\")\n",
        "\n",
        "print(\"\\nðŸ“¤ Uploaded to Drive\")\n",
        "\n",
        "# ============================================================\n",
        "# PLOT TRAINING CURVES\n",
        "# ============================================================\n",
        "def plot_history(h1, h2):\n",
        "    acc = h1.history[\"accuracy\"] + h2.history[\"accuracy\"]\n",
        "    val_acc = h1.history[\"val_accuracy\"] + h2.history[\"val_accuracy\"]\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(acc, label=\"train\")\n",
        "    plt.plot(val_acc, label=\"val\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history1, history2)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}